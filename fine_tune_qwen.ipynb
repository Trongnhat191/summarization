{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "%uv pip install datasets transformers peft trl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.10.19 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mdatasets==4.4.2                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtransformers==4.57.3                                                          \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpeft==0.18.0                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtrl==0.26.2                                                                   \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfilelock==3.20.2                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnumpy==2.2.6                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpyarrow==22.0.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mdill==0.4.0                                                                   \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpandas==2.3.3                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnumpy==2.2.6                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mhttpx==0.28.1                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mxxhash==3.6.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mmultiprocess==0.70.18                                                         \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfsspec==2025.10.0                                                             \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfsspec==2025.10.0                                                             \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mhuggingface-hub==0.36.0                                                       \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m68 packages\u001b[0m \u001b[2min 39ms\u001b[0m\u001b[0m\r\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\r\n",
            "\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mfsspec==2025.10.0                                    \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [1/1] \u001b[2mfsspec==2025.10.0                                    \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 59ms\u001b[0m\u001b[0m\r\n",
            " \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files={\n",
        "        \"train\": \"new_data1.json\",\n",
        "    }\n",
        ")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating train split: 0 examples [00:00, ? examples/s]\rGenerating train split: 10000 examples [00:00, 16227.13 examples/s]\rGenerating train split: 10000 examples [00:00, 16182.55 examples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "data = dataset[\"train\"]\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "Dataset({\n    features: ['Document', 'Summary'],\n    num_rows: 10000\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "#train test split\n",
        "data = data.train_test_split(test_size=0.1)\n",
        "train_data = data['train']\n",
        "test_data = data['test']\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "{'Document': '\u0110\u1eb7t m\u1ed9t b\u00e0n tay l\u00ean g\u1ed1c c\u00e2y lan \u0111\u1ec3 che mi\u1ec7ng ch\u1eadu, tay kia c\u1ea7m ch\u1eadu c\u00e2y v\u00e0 nh\u1eb9 nh\u00e0ng l\u1eadt c\u00e2y lan l\u1ea1i v\u00e0o b\u00e0n tay \u0111\u1ee1 c\u00e2y lan.  N\u1ebfu c\u00e2y lan b\u00e1m v\u00e0o ch\u1eadu, b\u1ea1n h\u00e3y lay nh\u1eb9 t\u1edbi lui \u0111\u1ec3 c\u00e2y long ra. Ch\u1ec9 c\u1eaft r\u1ec5 ho\u1eb7c c\u00e0nh c\u00e2y n\u1ebfu b\u1ea1n kh\u00f4ng th\u1ec3 l\u1eafc cho c\u00e2y long ra kh\u1ecfi ch\u1eadu. N\u1ebfu ph\u1ea3i c\u1eaft c\u00e2y, b\u1ea1n n\u00ean c\u1ed1 g\u1eafng b\u1ea3o t\u1ed3n r\u1ec5 v\u00e0 c\u00e0nh c\u00e0ng nhi\u1ec1u c\u00e0ng t\u1ed1t. V\u1eabn c\u1ea9n th\u1eadn c\u1ea7m c\u00e2y lan b\u1eb1ng m\u1ed9t tay, tay kia b\u1ea1n b\u00f3c gi\u00e1 th\u1ec3 c\u0169 \u0111\u01b0\u1ee3c c\u00e0ng nhi\u1ec1u c\u00e0ng t\u1ed1t. Khi \u0111\u00e3 lo\u1ea1i b\u1ecf \u0111\u01b0\u1ee3c c\u00e1c m\u1ea3ng gi\u00e1 th\u1ec3 l\u1edbn, b\u1ea1n h\u00e3y r\u1eeda r\u1ec5 c\u00e2y b\u1eb1ng n\u01b0\u1edbc \u1ea5m \u0111\u1ec3 lo\u1ea1i b\u1ecf ph\u1ea7n c\u00f2n l\u1ea1i. Vi\u1ec7c lo\u1ea1i b\u1ecf ho\u00e0n to\u00e0n gi\u00e1 th\u1ec3 c\u0169 s\u1ebd gi\u00fap c\u00e2y lan c\u00f3 th\u1ec3 h\u00fat t\u1ed1i \u0111a d\u01b0\u1ee1ng ch\u1ea5t khi \u0111\u01b0\u1ee3c tr\u1ed3ng l\u1ea1i v\u00e0o ch\u1eadu m\u1edbi, \u0111\u1ed3ng th\u1eddi \u0111\u1ea3m b\u1ea3o ti\u00eau di\u1ec7t h\u1ebft s\u00e2u b\u1ecd. Khi c\u00e2y lan \u0111\u00e3 \u0111\u01b0\u1ee3c r\u1eeda s\u1ea1ch, b\u1ea1n h\u00e3y ki\u1ec3m tra k\u1ef9 l\u01b0\u1ee1ng \u0111\u1ec3 t\u00ecm c\u00e1c l\u00e1, c\u00e0nh, r\u1ec5 v\u00e0 c\u1ee7 b\u1eb9 ch\u1ebft. D\u00f9ng d\u1ee5ng c\u1ee5 \u0111\u00e3 kh\u1eed tr\u00f9ng c\u1eaft b\u1ecf nh\u1eefng ph\u1ea7n r\u1ec5 m\u1ec1m v\u00e0 n\u00e2u, l\u00e1 c\u00e2y \u00faa v\u00e0ng v\u00e0 c\u00e1c c\u1ee7 b\u1eb9 \u0111en qu\u1eaft.  C\u1ee7 b\u1eb9 l\u00e0 m\u1ed9t \u0111\u1eb7c \u0111i\u1ec3m \u1edf m\u1ed9t s\u1ed1 lo\u00e0i lan. C\u1ee7 b\u1eb9 l\u00e0 b\u1ed9 ph\u1eadn c\u00f3 h\u00ecnh c\u1ee7 h\u00e0nh m\u1ecdc g\u1ea7n g\u1ed1c c\u00e2y m\u00e0 t\u1eeb \u0111\u00f3 l\u00e1 c\u00e2y s\u1ebd m\u1ecdc ra.  N\u1ebfu thay ch\u1eadu cho nhi\u1ec1u c\u00e2y lan c\u00f9ng l\u00fac, b\u1ea1n c\u1ea7n kh\u1eed tr\u00f9ng d\u1ee5ng c\u1ee5 c\u1eaft sau m\u1ed7i l\u1ea7n x\u1eed l\u00fd m\u1ed9t c\u00e2y b\u1eb1ng c\u00e1ch lau b\u1eb1ng thu\u1ed1c s\u00e1t tr\u00f9ng ho\u1eb7c h\u01a1 tr\u00ean l\u1eeda. Qu\u1ebf l\u00e0 m\u1ed9t ch\u1ea5t di\u1ec7t n\u1ea5m m\u1ea1nh c\u00f3 th\u1ec3 b\u1ea3o v\u1ec7 c\u00e2y lan kh\u1ecfi b\u1ecb nhi\u1ec5m tr\u00f9ng v\u00e0 th\u1ed1i r\u1eefa. B\u1ea1n h\u00e3y r\u1eafc b\u1ed9t qu\u1ebf l\u00ean c\u00e1c v\u1ebft c\u1eaft \u1edf r\u1ec5, c\u00e0nh, c\u1ee7 b\u1eb9 ho\u1eb7c l\u00e1 v\u1eeba c\u1eaft. B\u1ea1n c\u0169ng c\u00f3 th\u1ec3 d\u00f9ng thu\u1ed1c di\u1ec7t n\u1ea5m chuy\u00ean d\u00e0nh cho lan.',\n 'Summary': 'B\u00e0i vi\u1ebft h\u01b0\u1edbng d\u1eabn quy tr\u00ecnh thay ch\u1eadu cho c\u00e2y lan, b\u1eaft \u0111\u1ea7u b\u1eb1ng vi\u1ec7c nh\u1eb9 nh\u00e0ng t\u00e1ch c\u00e2y ra kh\u1ecfi ch\u1eadu c\u0169, c\u00f3 th\u1ec3 c\u1ea7n c\u1eaft r\u1ec5 ho\u1eb7c c\u00e0nh n\u1ebfu c\u00e2y b\u00e1m ch\u1eb7t. Sau khi t\u00e1ch c\u00e2y, c\u1ea7n lo\u1ea1i b\u1ecf ho\u00e0n to\u00e0n gi\u00e1 th\u1ec3 c\u0169 v\u00e0 r\u1eeda s\u1ea1ch r\u1ec5 b\u1eb1ng n\u01b0\u1edbc \u1ea5m \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00e2y h\u1ea5p th\u1ee5 dinh d\u01b0\u1ee1ng t\u1ed1t v\u00e0 lo\u1ea1i b\u1ecf s\u00e2u b\u1ecd. Ti\u1ebfp \u0111\u00f3, ng\u01b0\u1eddi tr\u1ed3ng c\u1ea7n ki\u1ec3m tra v\u00e0 c\u1eaft b\u1ecf c\u00e1c ph\u1ea7n l\u00e1, c\u00e0nh, r\u1ec5 ho\u1eb7c c\u1ee7 b\u1eb9 (b\u1ed9 ph\u1eadn \u0111\u1eb7c tr\u01b0ng c\u1ee7a m\u1ed9t s\u1ed1 lo\u00e0i lan) b\u1ecb h\u01b0 h\u1ecfng. Cu\u1ed1i c\u00f9ng, \u0111\u1ec3 ph\u00f2ng ng\u1eeba nhi\u1ec5m tr\u00f9ng, c\u1ea7n kh\u1eed tr\u00f9ng d\u1ee5ng c\u1ee5 c\u1eaft v\u00e0 s\u1eed d\u1ee5ng b\u1ed9t qu\u1ebf ho\u1eb7c thu\u1ed1c di\u1ec7t n\u1ea5m chuy\u00ean d\u1ee5ng cho lan l\u00ean c\u00e1c v\u1ebft c\u1eaft.\\n'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "%uv pip install -U bitsandbytes accelerate transformers"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.10.19 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mbitsandbytes==0.49.0                                                          \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2maccelerate==1.12.0                                                            \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtransformers==4.57.3                                                          \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtorch==2.9.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cuda-nvrtc-cu12==12.8.93                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cuda-nvrtc-cu12==12.8.93                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cuda-runtime-cu12==12.8.90                                             \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cuda-runtime-cu12==12.8.90                                             \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cuda-cupti-cu12==12.8.90                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cuda-cupti-cu12==12.8.90                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cudnn-cu12==9.10.2.21                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cudnn-cu12==9.10.2.21                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cublas-cu12==12.8.4.1                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cublas-cu12==12.8.4.1                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cufft-cu12==11.3.3.83                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cufft-cu12==11.3.3.83                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-curand-cu12==10.3.9.90                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-curand-cu12==10.3.9.90                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnvidia-cusolver-cu12==11.7.3.90                                               \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m43 packages\u001b[0m \u001b[2min 69ms\u001b[0m\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2m\u001b[0m (1/1)                                                                        \r\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 0.64ms\u001b[0m\u001b[0m\r\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\r\n",
            "\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mfsspec==2025.12.0                                    \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [1/1] \u001b[2mfsspec==2025.12.0                                    \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 56ms\u001b[0m\u001b[0m\r\n",
            " \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    # bnb_4bit_use_double_quant=False,\n",
        ")\n",
        "\n",
        "# 2. Load model v\u00e0 tokenizer\n",
        "model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    cache_dir=\"./base_model_cache\"\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rLoading checkpoint shards:   0%|                                                         | 0/3 [00:00<?, ?it/s]\rLoading checkpoint shards:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                | 1/3 [00:02<00:04,  2.44s/it]\rLoading checkpoint shards:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                | 2/3 [00:05<00:02,  2.59s/it]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:05<00:00,  1.74s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, use_fast = False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "tokenizer\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "Qwen2Tokenizer(name_or_path='Qwen/Qwen3-4B-Instruct-2507', vocab_size=151643, model_max_length=1010000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151665: AddedToken(\"<tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151666: AddedToken(\"</tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151667: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151668: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n}\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "def format_prompt(sample):\n",
        "    article = sample['Document'].strip()\n",
        "    summary = sample['Summary'].strip()\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"B\u1ea1n l\u00e0 m\u1ed9t bi\u00ean t\u1eadp vi\u00ean b\u00e1o ch\u00ed chuy\u00ean nghi\u1ec7p. Nhi\u1ec7m v\u1ee5 c\u1ee7a b\u1ea1n l\u00e0 t\u00f3m t\u1eaft b\u00e0i b\u00e1o \u0111\u01b0\u1ee3c cung c\u1ea5p. \"},\n",
        "        {\"role\": \"user\", \"content\": article},\n",
        "        {\"role\": \"assistant\", \"content\": summary}\n",
        "    ]\n",
        "\n",
        "    formatted_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "    return formatted_text\n",
        "        "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "\n",
        "print(format_prompt(train_data[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "B\u1ea1n l\u00e0 m\u1ed9t bi\u00ean t\u1eadp vi\u00ean b\u00e1o ch\u00ed chuy\u00ean nghi\u1ec7p. Nhi\u1ec7m v\u1ee5 c\u1ee7a b\u1ea1n l\u00e0 t\u00f3m t\u1eaft b\u00e0i b\u00e1o \u0111\u01b0\u1ee3c cung c\u1ea5p. <|im_end|>\n",
            "<|im_start|>user\n",
            "\u0110\u1eb7t m\u1ed9t b\u00e0n tay l\u00ean g\u1ed1c c\u00e2y lan \u0111\u1ec3 che mi\u1ec7ng ch\u1eadu, tay kia c\u1ea7m ch\u1eadu c\u00e2y v\u00e0 nh\u1eb9 nh\u00e0ng l\u1eadt c\u00e2y lan l\u1ea1i v\u00e0o b\u00e0n tay \u0111\u1ee1 c\u00e2y lan.  N\u1ebfu c\u00e2y lan b\u00e1m v\u00e0o ch\u1eadu, b\u1ea1n h\u00e3y lay nh\u1eb9 t\u1edbi lui \u0111\u1ec3 c\u00e2y long ra. Ch\u1ec9 c\u1eaft r\u1ec5 ho\u1eb7c c\u00e0nh c\u00e2y n\u1ebfu b\u1ea1n kh\u00f4ng th\u1ec3 l\u1eafc cho c\u00e2y long ra kh\u1ecfi ch\u1eadu. N\u1ebfu ph\u1ea3i c\u1eaft c\u00e2y, b\u1ea1n n\u00ean c\u1ed1 g\u1eafng b\u1ea3o t\u1ed3n r\u1ec5 v\u00e0 c\u00e0nh c\u00e0ng nhi\u1ec1u c\u00e0ng t\u1ed1t. V\u1eabn c\u1ea9n th\u1eadn c\u1ea7m c\u00e2y lan b\u1eb1ng m\u1ed9t tay, tay kia b\u1ea1n b\u00f3c gi\u00e1 th\u1ec3 c\u0169 \u0111\u01b0\u1ee3c c\u00e0ng nhi\u1ec1u c\u00e0ng t\u1ed1t. Khi \u0111\u00e3 lo\u1ea1i b\u1ecf \u0111\u01b0\u1ee3c c\u00e1c m\u1ea3ng gi\u00e1 th\u1ec3 l\u1edbn, b\u1ea1n h\u00e3y r\u1eeda r\u1ec5 c\u00e2y b\u1eb1ng n\u01b0\u1edbc \u1ea5m \u0111\u1ec3 lo\u1ea1i b\u1ecf ph\u1ea7n c\u00f2n l\u1ea1i. Vi\u1ec7c lo\u1ea1i b\u1ecf ho\u00e0n to\u00e0n gi\u00e1 th\u1ec3 c\u0169 s\u1ebd gi\u00fap c\u00e2y lan c\u00f3 th\u1ec3 h\u00fat t\u1ed1i \u0111a d\u01b0\u1ee1ng ch\u1ea5t khi \u0111\u01b0\u1ee3c tr\u1ed3ng l\u1ea1i v\u00e0o ch\u1eadu m\u1edbi, \u0111\u1ed3ng th\u1eddi \u0111\u1ea3m b\u1ea3o ti\u00eau di\u1ec7t h\u1ebft s\u00e2u b\u1ecd. Khi c\u00e2y lan \u0111\u00e3 \u0111\u01b0\u1ee3c r\u1eeda s\u1ea1ch, b\u1ea1n h\u00e3y ki\u1ec3m tra k\u1ef9 l\u01b0\u1ee1ng \u0111\u1ec3 t\u00ecm c\u00e1c l\u00e1, c\u00e0nh, r\u1ec5 v\u00e0 c\u1ee7 b\u1eb9 ch\u1ebft. D\u00f9ng d\u1ee5ng c\u1ee5 \u0111\u00e3 kh\u1eed tr\u00f9ng c\u1eaft b\u1ecf nh\u1eefng ph\u1ea7n r\u1ec5 m\u1ec1m v\u00e0 n\u00e2u, l\u00e1 c\u00e2y \u00faa v\u00e0ng v\u00e0 c\u00e1c c\u1ee7 b\u1eb9 \u0111en qu\u1eaft.  C\u1ee7 b\u1eb9 l\u00e0 m\u1ed9t \u0111\u1eb7c \u0111i\u1ec3m \u1edf m\u1ed9t s\u1ed1 lo\u00e0i lan. C\u1ee7 b\u1eb9 l\u00e0 b\u1ed9 ph\u1eadn c\u00f3 h\u00ecnh c\u1ee7 h\u00e0nh m\u1ecdc g\u1ea7n g\u1ed1c c\u00e2y m\u00e0 t\u1eeb \u0111\u00f3 l\u00e1 c\u00e2y s\u1ebd m\u1ecdc ra.  N\u1ebfu thay ch\u1eadu cho nhi\u1ec1u c\u00e2y lan c\u00f9ng l\u00fac, b\u1ea1n c\u1ea7n kh\u1eed tr\u00f9ng d\u1ee5ng c\u1ee5 c\u1eaft sau m\u1ed7i l\u1ea7n x\u1eed l\u00fd m\u1ed9t c\u00e2y b\u1eb1ng c\u00e1ch lau b\u1eb1ng thu\u1ed1c s\u00e1t tr\u00f9ng ho\u1eb7c h\u01a1 tr\u00ean l\u1eeda. Qu\u1ebf l\u00e0 m\u1ed9t ch\u1ea5t di\u1ec7t n\u1ea5m m\u1ea1nh c\u00f3 th\u1ec3 b\u1ea3o v\u1ec7 c\u00e2y lan kh\u1ecfi b\u1ecb nhi\u1ec5m tr\u00f9ng v\u00e0 th\u1ed1i r\u1eefa. B\u1ea1n h\u00e3y r\u1eafc b\u1ed9t qu\u1ebf l\u00ean c\u00e1c v\u1ebft c\u1eaft \u1edf r\u1ec5, c\u00e0nh, c\u1ee7 b\u1eb9 ho\u1eb7c l\u00e1 v\u1eeba c\u1eaft. B\u1ea1n c\u0169ng c\u00f3 th\u1ec3 d\u00f9ng thu\u1ed1c di\u1ec7t n\u1ea5m chuy\u00ean d\u00e0nh cho lan.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "B\u00e0i vi\u1ebft h\u01b0\u1edbng d\u1eabn quy tr\u00ecnh thay ch\u1eadu cho c\u00e2y lan, b\u1eaft \u0111\u1ea7u b\u1eb1ng vi\u1ec7c nh\u1eb9 nh\u00e0ng t\u00e1ch c\u00e2y ra kh\u1ecfi ch\u1eadu c\u0169, c\u00f3 th\u1ec3 c\u1ea7n c\u1eaft r\u1ec5 ho\u1eb7c c\u00e0nh n\u1ebfu c\u00e2y b\u00e1m ch\u1eb7t. Sau khi t\u00e1ch c\u00e2y, c\u1ea7n lo\u1ea1i b\u1ecf ho\u00e0n to\u00e0n gi\u00e1 th\u1ec3 c\u0169 v\u00e0 r\u1eeda s\u1ea1ch r\u1ec5 b\u1eb1ng n\u01b0\u1edbc \u1ea5m \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00e2y h\u1ea5p th\u1ee5 dinh d\u01b0\u1ee1ng t\u1ed1t v\u00e0 lo\u1ea1i b\u1ecf s\u00e2u b\u1ecd. Ti\u1ebfp \u0111\u00f3, ng\u01b0\u1eddi tr\u1ed3ng c\u1ea7n ki\u1ec3m tra v\u00e0 c\u1eaft b\u1ecf c\u00e1c ph\u1ea7n l\u00e1, c\u00e0nh, r\u1ec5 ho\u1eb7c c\u1ee7 b\u1eb9 (b\u1ed9 ph\u1eadn \u0111\u1eb7c tr\u01b0ng c\u1ee7a m\u1ed9t s\u1ed1 lo\u00e0i lan) b\u1ecb h\u01b0 h\u1ecfng. Cu\u1ed1i c\u00f9ng, \u0111\u1ec3 ph\u00f2ng ng\u1eeba nhi\u1ec5m tr\u00f9ng, c\u1ea7n kh\u1eed tr\u00f9ng d\u1ee5ng c\u1ee5 c\u1eaft v\u00e0 s\u1eed d\u1ee5ng b\u1ed9t qu\u1ebf ho\u1eb7c thu\u1ed1c di\u1ec7t n\u1ea5m chuy\u00ean d\u1ee5ng cho lan l\u00ean c\u00e1c v\u1ebft c\u1eaft.<|im_end|>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lora config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                   \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/qwen-lora-summarization\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=4,  # \u0110i\u1ec1u ch\u1ec9nh theo VRAM c\u1ee7a b\u1ea1n\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=5e-5,\n",
        "    bf16=True,  # Thay b\u1eb1ng fp16=True n\u1ebfu GPU kh\u00f4ng h\u1ed7 tr\u1ee3 bf16\n",
        "    fp16=False,\n",
        "    logging_steps=20,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    save_steps=200,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    report_to = 'none',\n",
        "    optim = 'paged_adamw_32bit'\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    args=training_args,\n",
        "    peft_config=lora_config,\n",
        "    formatting_func=format_prompt,\n",
        "    # max_seq_length=512,\n",
        "    # packing=True,  # T\u0103ng hi\u1ec7u su\u1ea5t training\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rApplying formatting function to train dataset:   0%|                           | 0/9000 [00:00<?, ? examples/s]\rApplying formatting function to train dataset:   7%|\u2588              | 663/9000 [00:00<00:01, 6566.27 examples/s]\rApplying formatting function to train dataset:  17%|\u2588\u2588\u258e           | 1504/9000 [00:00<00:01, 5908.21 examples/s]\rApplying formatting function to train dataset:  26%|\u2588\u2588\u2588\u258b          | 2368/9000 [00:00<00:01, 5832.36 examples/s]\rApplying formatting function to train dataset:  33%|\u2588\u2588\u2588\u2588\u258b         | 3000/9000 [00:00<00:01, 5696.18 examples/s]\rApplying formatting function to train dataset:  41%|\u2588\u2588\u2588\u2588\u2588\u258b        | 3677/9000 [00:00<00:00, 6019.55 examples/s]\rApplying formatting function to train dataset:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a       | 4345/9000 [00:00<00:00, 5898.10 examples/s]\rApplying formatting function to train dataset:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a      | 5000/9000 [00:00<00:00, 5818.10 examples/s]\rApplying formatting function to train dataset:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a     | 5688/9000 [00:00<00:00, 6116.63 examples/s]\rApplying formatting function to train dataset:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a    | 6347/9000 [00:01<00:00, 5978.00 examples/s]\rApplying formatting function to train dataset:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 7000/9000 [00:01<00:00, 5871.68 examples/s]\rApplying formatting function to train dataset:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 7682/9000 [00:01<00:00, 6134.94 examples/s]\rApplying formatting function to train dataset:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 8348/9000 [00:01<00:00, 5995.53 examples/s]\rApplying formatting function to train dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9000/9000 [00:01<00:00, 5866.63 examples/s]\rApplying formatting function to train dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9000/9000 [00:01<00:00, 5920.62 examples/s]\n",
            "\rAdding EOS to train dataset:   0%|                                             | 0/9000 [00:00<?, ? examples/s]\rAdding EOS to train dataset:  12%|\u2588\u2588\u2588\u258a                           | 1119/9000 [00:00<00:00, 11123.26 examples/s]\rAdding EOS to train dataset:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                       | 2238/9000 [00:00<00:00, 11157.85 examples/s]\rAdding EOS to train dataset:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                  | 3791/9000 [00:00<00:00, 11550.85 examples/s]\rAdding EOS to train dataset:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f            | 5283/9000 [00:00<00:00, 10806.67 examples/s]\rAdding EOS to train dataset:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d       | 6802/9000 [00:00<00:00, 11344.60 examples/s]\rAdding EOS to train dataset:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 8293/9000 [00:00<00:00, 10809.07 examples/s]\rAdding EOS to train dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9000/9000 [00:00<00:00, 10839.22 examples/s]\n",
            "\rTokenizing train dataset:   0%|                                                | 0/9000 [00:00<?, ? examples/s]\rTokenizing train dataset:   0%|                                      | 20/9000 [00:00<00:47, 188.60 examples/s]\rTokenizing train dataset:   1%|\u258f                                     | 47/9000 [00:00<00:51, 175.05 examples/s]\rTokenizing train dataset:   1%|\u258e                                     | 68/9000 [00:00<00:48, 182.89 examples/s]\rTokenizing train dataset:   1%|\u258d                                     | 91/9000 [00:00<00:45, 197.26 examples/s]\rTokenizing train dataset:   1%|\u258d                                    | 115/9000 [00:00<00:43, 203.42 examples/s]\rTokenizing train dataset:   2%|\u258c                                    | 137/9000 [00:00<00:43, 202.95 examples/s]\rTokenizing train dataset:   2%|\u258b                                    | 160/9000 [00:00<00:42, 209.76 examples/s]\rTokenizing train dataset:   2%|\u258b                                    | 182/9000 [00:00<00:41, 209.99 examples/s]\rTokenizing train dataset:   2%|\u258a                                    | 212/9000 [00:01<00:43, 203.72 examples/s]\rTokenizing train dataset:   3%|\u2589                                    | 234/9000 [00:01<00:42, 204.27 examples/s]\rTokenizing train dataset:   3%|\u2588                                    | 265/9000 [00:01<00:43, 201.55 examples/s]\rTokenizing train dataset:   3%|\u2588\u258f                                   | 287/9000 [00:01<00:43, 202.10 examples/s]\rTokenizing train dataset:   3%|\u2588\u258e                                   | 310/9000 [00:01<00:41, 207.15 examples/s]\rTokenizing train dataset:   4%|\u2588\u258e                                   | 333/9000 [00:01<00:41, 210.70 examples/s]\rTokenizing train dataset:   4%|\u2588\u258c                                   | 365/9000 [00:01<00:41, 206.45 examples/s]\rTokenizing train dataset:   4%|\u2588\u258c                                   | 387/9000 [00:01<00:42, 204.70 examples/s]\rTokenizing train dataset:   5%|\u2588\u258b                                   | 410/9000 [00:02<00:41, 207.99 examples/s]\rTokenizing train dataset:   5%|\u2588\u258a                                   | 434/9000 [00:02<00:40, 213.22 examples/s]\rTokenizing train dataset:   5%|\u2588\u2589                                   | 458/9000 [00:02<00:39, 217.73 examples/s]\rTokenizing train dataset:   5%|\u2588\u2589                                   | 480/9000 [00:02<00:39, 216.56 examples/s]\rTokenizing train dataset:   6%|\u2588\u2588                                   | 504/9000 [00:02<00:38, 218.77 examples/s]\rTokenizing train dataset:   6%|\u2588\u2588\u258f                                  | 527/9000 [00:02<00:38, 219.43 examples/s]\rTokenizing train dataset:   6%|\u2588\u2588\u258e                                  | 551/9000 [00:02<00:37, 223.46 examples/s]\rTokenizing train dataset:   6%|\u2588\u2588\u258e                                  | 575/9000 [00:02<00:37, 226.65 examples/s]\rTokenizing train dataset:   7%|\u2588\u2588\u258d                                  | 600/9000 [00:02<00:36, 230.97 examples/s]\rTokenizing train dataset:   7%|\u2588\u2588\u258c                                  | 636/9000 [00:03<00:36, 232.12 examples/s]\rTokenizing train dataset:   7%|\u2588\u2588\u258b                                  | 660/9000 [00:03<00:35, 231.99 examples/s]\rTokenizing train dataset:   8%|\u2588\u2588\u258a                                  | 695/9000 [00:03<00:36, 225.97 examples/s]\rTokenizing train dataset:   8%|\u2588\u2588\u2589                                  | 719/9000 [00:03<00:36, 226.89 examples/s]\rTokenizing train dataset:   8%|\u2588\u2588\u2588                                  | 751/9000 [00:03<00:37, 218.42 examples/s]\rTokenizing train dataset:   9%|\u2588\u2588\u2588\u258f                                 | 775/9000 [00:03<00:37, 219.89 examples/s]\rTokenizing train dataset:   9%|\u2588\u2588\u2588\u258e                                 | 798/9000 [00:03<00:37, 217.70 examples/s]\rTokenizing train dataset:   9%|\u2588\u2588\u2588\u258d                                 | 822/9000 [00:03<00:37, 220.75 examples/s]\rTokenizing train dataset:  10%|\u2588\u2588\u2588\u258c                                 | 857/9000 [00:04<00:36, 221.79 examples/s]\rTokenizing train dataset:  10%|\u2588\u2588\u2588\u258c                                 | 881/9000 [00:04<00:36, 220.63 examples/s]\rTokenizing train dataset:  10%|\u2588\u2588\u2588\u258b                                 | 906/9000 [00:04<00:35, 224.97 examples/s]\rTokenizing train dataset:  10%|\u2588\u2588\u2588\u258a                                 | 930/9000 [00:04<00:35, 227.26 examples/s]\rTokenizing train dataset:  11%|\u2588\u2588\u2588\u2589                                 | 953/9000 [00:04<00:36, 223.09 examples/s]\rTokenizing train dataset:  11%|\u2588\u2588\u2588\u2588                                 | 987/9000 [00:04<00:36, 220.33 examples/s]\rTokenizing train dataset:  11%|\u2588\u2588\u2588\u2588                                | 1011/9000 [00:04<00:44, 179.02 examples/s]\rTokenizing train dataset:  11%|\u2588\u2588\u2588\u2588\u258f                               | 1033/9000 [00:04<00:42, 186.83 examples/s]\rTokenizing train dataset:  12%|\u2588\u2588\u2588\u2588\u258f                               | 1054/9000 [00:05<00:41, 189.76 examples/s]\rTokenizing train dataset:  12%|\u2588\u2588\u2588\u2588\u258e                               | 1075/9000 [00:05<00:40, 193.42 examples/s]\rTokenizing train dataset:  12%|\u2588\u2588\u2588\u2588\u258d                               | 1098/9000 [00:05<00:39, 200.09 examples/s]\rTokenizing train dataset:  12%|\u2588\u2588\u2588\u2588\u258d                               | 1120/9000 [00:05<00:38, 202.70 examples/s]\rTokenizing train dataset:  13%|\u2588\u2588\u2588\u2588\u258c                               | 1144/9000 [00:05<00:37, 209.32 examples/s]\rTokenizing train dataset:  13%|\u2588\u2588\u2588\u2588\u258b                               | 1176/9000 [00:05<00:37, 207.03 examples/s]\rTokenizing train dataset:  13%|\u2588\u2588\u2588\u2588\u258a                               | 1198/9000 [00:05<00:37, 207.18 examples/s]\rTokenizing train dataset:  14%|\u2588\u2588\u2588\u2588\u2589                               | 1223/9000 [00:05<00:36, 214.06 examples/s]\rTokenizing train dataset:  14%|\u2588\u2588\u2588\u2588\u2589                               | 1247/9000 [00:05<00:35, 216.52 examples/s]\rTokenizing train dataset:  14%|\u2588\u2588\u2588\u2588\u2588                               | 1272/9000 [00:06<00:34, 223.60 examples/s]\rTokenizing train dataset:  15%|\u2588\u2588\u2588\u2588\u2588\u258f                              | 1307/9000 [00:06<00:34, 222.68 examples/s]\rTokenizing train dataset:  15%|\u2588\u2588\u2588\u2588\u2588\u258e                              | 1330/9000 [00:06<00:34, 222.02 examples/s]\rTokenizing train dataset:  15%|\u2588\u2588\u2588\u2588\u2588\u258d                              | 1354/9000 [00:06<00:34, 221.42 examples/s]\rTokenizing train dataset:  15%|\u2588\u2588\u2588\u2588\u2588\u258c                              | 1378/9000 [00:06<00:33, 224.55 examples/s]\rTokenizing train dataset:  16%|\u2588\u2588\u2588\u2588\u2588\u258c                              | 1404/9000 [00:06<00:33, 228.56 examples/s]\rTokenizing train dataset:  16%|\u2588\u2588\u2588\u2588\u2588\u258b                              | 1428/9000 [00:06<00:33, 228.74 examples/s]\rTokenizing train dataset:  16%|\u2588\u2588\u2588\u2588\u2588\u258a                              | 1463/9000 [00:06<00:33, 226.06 examples/s]\rTokenizing train dataset:  17%|\u2588\u2588\u2588\u2588\u2588\u2589                              | 1497/9000 [00:07<00:33, 223.34 examples/s]\rTokenizing train dataset:  17%|\u2588\u2588\u2588\u2588\u2588\u2588                              | 1520/9000 [00:07<00:34, 219.53 examples/s]\rTokenizing train dataset:  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f                             | 1543/9000 [00:07<00:34, 218.58 examples/s]\rTokenizing train dataset:  18%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e                             | 1576/9000 [00:07<00:34, 216.99 examples/s]\rTokenizing train dataset:  18%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d                             | 1601/9000 [00:07<00:33, 222.88 examples/s]\rTokenizing train dataset:  18%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c                             | 1632/9000 [00:07<00:34, 216.04 examples/s]\rTokenizing train dataset:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b                             | 1666/9000 [00:07<00:34, 215.33 examples/s]\rTokenizing train dataset:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a                             | 1688/9000 [00:07<00:34, 214.36 examples/s]\rTokenizing train dataset:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a                             | 1712/9000 [00:08<00:33, 216.79 examples/s]\rTokenizing train dataset:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589                             | 1735/9000 [00:08<00:33, 215.62 examples/s]\rTokenizing train dataset:  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588                             | 1766/9000 [00:08<00:34, 210.02 examples/s]\rTokenizing train dataset:  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                            | 1792/9000 [00:08<00:32, 218.68 examples/s]\rTokenizing train dataset:  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                            | 1816/9000 [00:08<00:32, 222.43 examples/s]\rTokenizing train dataset:  20%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                            | 1840/9000 [00:08<00:31, 223.81 examples/s]\rTokenizing train dataset:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                            | 1864/9000 [00:08<00:31, 226.54 examples/s]\rTokenizing train dataset:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 1888/9000 [00:08<00:31, 224.23 examples/s]\rTokenizing train dataset:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                            | 1923/9000 [00:08<00:31, 222.99 examples/s]\rTokenizing train dataset:  22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                            | 1947/9000 [00:09<00:31, 224.94 examples/s]\rTokenizing train dataset:  22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                            | 1979/9000 [00:09<00:32, 217.94 examples/s]\rTokenizing train dataset:  22%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                            | 2010/9000 [00:09<00:38, 182.09 examples/s]\rTokenizing train dataset:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                           | 2032/9000 [00:09<00:36, 188.81 examples/s]\rTokenizing train dataset:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                           | 2058/9000 [00:09<00:34, 200.56 examples/s]\rTokenizing train dataset:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                           | 2081/9000 [00:09<00:33, 203.56 examples/s]\rTokenizing train dataset:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                           | 2103/9000 [00:09<00:33, 206.29 examples/s]\rTokenizing train dataset:  24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                           | 2126/9000 [00:09<00:32, 209.54 examples/s]\rTokenizing train dataset:  24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                           | 2160/9000 [00:10<00:32, 212.42 examples/s]\rTokenizing train dataset:  24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                           | 2184/9000 [00:10<00:31, 216.04 examples/s]\rTokenizing train dataset:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                           | 2206/9000 [00:10<00:31, 215.12 examples/s]\rTokenizing train dataset:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                           | 2229/9000 [00:10<00:31, 215.09 examples/s]\rTokenizing train dataset:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                           | 2263/9000 [00:10<00:31, 215.80 examples/s]\rTokenizing train dataset:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                          | 2286/9000 [00:10<00:30, 218.23 examples/s]\rTokenizing train dataset:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                          | 2309/9000 [00:10<00:30, 218.77 examples/s]\rTokenizing train dataset:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                          | 2333/9000 [00:10<00:30, 220.87 examples/s]\rTokenizing train dataset:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                          | 2357/9000 [00:11<00:29, 225.50 examples/s]\rTokenizing train dataset:  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                          | 2390/9000 [00:11<00:30, 218.75 examples/s]\rTokenizing train dataset:  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                          | 2423/9000 [00:11<00:30, 215.88 examples/s]\rTokenizing train dataset:  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                          | 2448/9000 [00:11<00:29, 220.67 examples/s]\rTokenizing train dataset:  27%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                          | 2471/9000 [00:11<00:29, 219.49 examples/s]\rTokenizing train dataset:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                          | 2496/9000 [00:11<00:29, 223.56 examples/s]\rTokenizing train dataset:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                          | 2528/9000 [00:11<00:30, 215.28 examples/s]\rTokenizing train dataset:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                         | 2551/9000 [00:11<00:30, 213.44 examples/s]\rTokenizing train dataset:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                         | 2574/9000 [00:12<00:29, 215.24 examples/s]\rTokenizing train dataset:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                         | 2597/9000 [00:12<00:29, 216.34 examples/s]\rTokenizing train dataset:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                         | 2620/9000 [00:12<00:29, 217.81 examples/s]\rTokenizing train dataset:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                         | 2643/9000 [00:12<00:29, 216.68 examples/s]\rTokenizing train dataset:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                         | 2665/9000 [00:12<00:29, 216.28 examples/s]\rTokenizing train dataset:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                         | 2687/9000 [00:12<00:29, 215.05 examples/s]\rTokenizing train dataset:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                         | 2709/9000 [00:12<00:29, 215.29 examples/s]\rTokenizing train dataset:  30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                         | 2731/9000 [00:12<00:29, 213.63 examples/s]\rTokenizing train dataset:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                         | 2755/9000 [00:12<00:28, 216.23 examples/s]\rTokenizing train dataset:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                         | 2777/9000 [00:12<00:28, 216.78 examples/s]\rTokenizing train dataset:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                        | 2800/9000 [00:13<00:28, 216.75 examples/s]\rTokenizing train dataset:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                        | 2825/9000 [00:13<00:28, 219.02 examples/s]\rTokenizing train dataset:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                        | 2853/9000 [00:13<00:26, 233.78 examples/s]\rTokenizing train dataset:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                        | 2877/9000 [00:13<00:26, 231.66 examples/s]\rTokenizing train dataset:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                        | 2912/9000 [00:13<00:26, 227.56 examples/s]\rTokenizing train dataset:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                        | 2946/9000 [00:13<00:26, 224.82 examples/s]\rTokenizing train dataset:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                        | 2971/9000 [00:13<00:26, 228.16 examples/s]\rTokenizing train dataset:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                        | 3000/9000 [00:14<00:32, 186.12 examples/s]\rTokenizing train dataset:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                        | 3022/9000 [00:14<00:31, 190.54 examples/s]\rTokenizing train dataset:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                       | 3054/9000 [00:14<00:30, 195.09 examples/s]\rTokenizing train dataset:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                       | 3076/9000 [00:14<00:29, 198.58 examples/s]\rTokenizing train dataset:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                       | 3097/9000 [00:14<00:29, 199.51 examples/s]\rTokenizing train dataset:  35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                       | 3121/9000 [00:14<00:28, 208.06 examples/s]\rTokenizing train dataset:  35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                       | 3145/9000 [00:14<00:27, 215.53 examples/s]\rTokenizing train dataset:  35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                       | 3178/9000 [00:14<00:27, 211.98 examples/s]\rTokenizing train dataset:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                       | 3203/9000 [00:14<00:26, 217.41 examples/s]\rTokenizing train dataset:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                       | 3226/9000 [00:15<00:26, 216.91 examples/s]\rTokenizing train dataset:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                       | 3249/9000 [00:15<00:26, 218.32 examples/s]\rTokenizing train dataset:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                       | 3273/9000 [00:15<00:25, 221.77 examples/s]\rTokenizing train dataset:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                      | 3307/9000 [00:15<00:26, 216.94 examples/s]\rTokenizing train dataset:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                      | 3331/9000 [00:15<00:25, 220.69 examples/s]\rTokenizing train dataset:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                      | 3364/9000 [00:15<00:25, 218.64 examples/s]\rTokenizing train dataset:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                      | 3387/9000 [00:15<00:25, 217.81 examples/s]\rTokenizing train dataset:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                      | 3411/9000 [00:15<00:25, 220.20 examples/s]\rTokenizing train dataset:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                      | 3436/9000 [00:16<00:24, 226.66 examples/s]\rTokenizing train dataset:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                      | 3459/9000 [00:16<00:24, 224.95 examples/s]\rTokenizing train dataset:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                      | 3490/9000 [00:16<00:25, 215.60 examples/s]\rTokenizing train dataset:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                      | 3514/9000 [00:16<00:25, 219.42 examples/s]\rTokenizing train dataset:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                     | 3540/9000 [00:16<00:24, 226.63 examples/s]\rTokenizing train dataset:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                     | 3573/9000 [00:16<00:24, 218.18 examples/s]\rTokenizing train dataset:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                     | 3605/9000 [00:16<00:25, 214.72 examples/s]\rTokenizing train dataset:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 3628/9000 [00:16<00:24, 215.65 examples/s]\rTokenizing train dataset:  41%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                     | 3650/9000 [00:17<00:24, 214.47 examples/s]\rTokenizing train dataset:  41%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                     | 3674/9000 [00:17<00:24, 219.37 examples/s]\rTokenizing train dataset:  41%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                     | 3708/9000 [00:17<00:24, 219.89 examples/s]\rTokenizing train dataset:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                     | 3743/9000 [00:17<00:24, 217.25 examples/s]\rTokenizing train dataset:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                     | 3766/9000 [00:17<00:23, 218.23 examples/s]\rTokenizing train dataset:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                    | 3788/9000 [00:17<00:24, 215.99 examples/s]\rTokenizing train dataset:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 3815/9000 [00:17<00:22, 226.84 examples/s]\rTokenizing train dataset:  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 3841/9000 [00:17<00:22, 232.65 examples/s]\rTokenizing train dataset:  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                    | 3873/9000 [00:18<00:23, 221.94 examples/s]\rTokenizing train dataset:  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                    | 3897/9000 [00:18<00:22, 223.72 examples/s]\rTokenizing train dataset:  44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                    | 3920/9000 [00:18<00:22, 223.85 examples/s]\rTokenizing train dataset:  44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                    | 3953/9000 [00:18<00:23, 218.98 examples/s]\rTokenizing train dataset:  44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                    | 3979/9000 [00:18<00:22, 224.65 examples/s]\rTokenizing train dataset:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 4011/9000 [00:18<00:27, 184.75 examples/s]\rTokenizing train dataset:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 4031/9000 [00:18<00:26, 186.84 examples/s]\rTokenizing train dataset:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                   | 4051/9000 [00:18<00:26, 188.28 examples/s]\rTokenizing train dataset:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                   | 4074/9000 [00:19<00:25, 195.86 examples/s]\rTokenizing train dataset:  46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                   | 4100/9000 [00:19<00:23, 209.72 examples/s]\rTokenizing train dataset:  46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                   | 4123/9000 [00:19<00:23, 210.44 examples/s]\rTokenizing train dataset:  46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                   | 4146/9000 [00:19<00:22, 212.54 examples/s]\rTokenizing train dataset:  46%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                   | 4170/9000 [00:19<00:22, 217.28 examples/s]\rTokenizing train dataset:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                   | 4192/9000 [00:19<00:22, 215.82 examples/s]\rTokenizing train dataset:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                   | 4217/9000 [00:19<00:21, 222.55 examples/s]\rTokenizing train dataset:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                   | 4241/9000 [00:19<00:21, 224.87 examples/s]\rTokenizing train dataset:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                   | 4267/9000 [00:19<00:20, 233.31 examples/s]\rTokenizing train dataset:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                  | 4291/9000 [00:19<00:20, 231.19 examples/s]\rTokenizing train dataset:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                  | 4323/9000 [00:20<00:21, 221.88 examples/s]\rTokenizing train dataset:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                  | 4358/9000 [00:20<00:20, 221.76 examples/s]\rTokenizing train dataset:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                  | 4381/9000 [00:20<00:21, 218.46 examples/s]\rTokenizing train dataset:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                  | 4404/9000 [00:20<00:20, 220.13 examples/s]\rTokenizing train dataset:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                  | 4429/9000 [00:20<00:20, 221.45 examples/s]\rTokenizing train dataset:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                  | 4462/9000 [00:20<00:20, 216.98 examples/s]\rTokenizing train dataset:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                  | 4484/9000 [00:20<00:20, 216.93 examples/s]\rTokenizing train dataset:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                  | 4516/9000 [00:21<00:20, 213.96 examples/s]\rTokenizing train dataset:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                 | 4538/9000 [00:21<00:21, 211.57 examples/s]\rTokenizing train dataset:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                 | 4562/9000 [00:21<00:20, 217.02 examples/s]\rTokenizing train dataset:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                 | 4584/9000 [00:21<00:20, 215.88 examples/s]\rTokenizing train dataset:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                 | 4607/9000 [00:21<00:20, 216.15 examples/s]\rTokenizing train dataset:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                 | 4631/9000 [00:21<00:20, 217.43 examples/s]\rTokenizing train dataset:  52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                 | 4664/9000 [00:21<00:20, 216.45 examples/s]\rTokenizing train dataset:  52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 4690/9000 [00:21<00:19, 225.45 examples/s]\rTokenizing train dataset:  52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                 | 4714/9000 [00:21<00:18, 226.00 examples/s]\rTokenizing train dataset:  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                 | 4740/9000 [00:22<00:18, 230.93 examples/s]\rTokenizing train dataset:  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                 | 4764/9000 [00:22<00:18, 230.78 examples/s]\rTokenizing train dataset:  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                | 4798/9000 [00:22<00:18, 226.79 examples/s]\rTokenizing train dataset:  54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                | 4834/9000 [00:22<00:18, 227.96 examples/s]\rTokenizing train dataset:  54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                | 4857/9000 [00:22<00:18, 226.19 examples/s]\rTokenizing train dataset:  54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                | 4890/9000 [00:22<00:18, 219.04 examples/s]\rTokenizing train dataset:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                | 4922/9000 [00:22<00:19, 212.14 examples/s]\rTokenizing train dataset:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                | 4944/9000 [00:22<00:19, 211.81 examples/s]\rTokenizing train dataset:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                | 4968/9000 [00:23<00:18, 216.70 examples/s]\rTokenizing train dataset:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                | 4992/9000 [00:23<00:18, 221.26 examples/s]\rTokenizing train dataset:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                | 5024/9000 [00:23<00:21, 184.40 examples/s]\rTokenizing train dataset:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f               | 5048/9000 [00:23<00:20, 192.34 examples/s]\rTokenizing train dataset:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e               | 5071/9000 [00:23<00:19, 197.03 examples/s]\rTokenizing train dataset:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d               | 5095/9000 [00:23<00:18, 206.17 examples/s]\rTokenizing train dataset:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d               | 5119/9000 [00:23<00:18, 211.93 examples/s]\rTokenizing train dataset:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c               | 5144/9000 [00:23<00:17, 219.11 examples/s]\rTokenizing train dataset:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b               | 5176/9000 [00:24<00:17, 214.54 examples/s]\rTokenizing train dataset:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a               | 5198/9000 [00:24<00:17, 213.74 examples/s]\rTokenizing train dataset:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589               | 5221/9000 [00:24<00:17, 215.73 examples/s]\rTokenizing train dataset:  58%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589               | 5245/9000 [00:24<00:17, 220.04 examples/s]\rTokenizing train dataset:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588               | 5269/9000 [00:24<00:16, 221.20 examples/s]\rTokenizing train dataset:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f              | 5293/9000 [00:24<00:16, 222.00 examples/s]\rTokenizing train dataset:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e              | 5317/9000 [00:24<00:16, 225.12 examples/s]\rTokenizing train dataset:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e              | 5341/9000 [00:24<00:16, 225.09 examples/s]\rTokenizing train dataset:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d              | 5367/9000 [00:24<00:15, 230.02 examples/s]\rTokenizing train dataset:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c              | 5393/9000 [00:25<00:15, 236.42 examples/s]\rTokenizing train dataset:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b              | 5426/9000 [00:25<00:15, 225.70 examples/s]\rTokenizing train dataset:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a              | 5449/9000 [00:25<00:15, 223.96 examples/s]\rTokenizing train dataset:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589              | 5474/9000 [00:25<00:15, 228.43 examples/s]\rTokenizing train dataset:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588              | 5500/9000 [00:25<00:15, 231.22 examples/s]\rTokenizing train dataset:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588              | 5524/9000 [00:25<00:15, 230.71 examples/s]\rTokenizing train dataset:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f             | 5548/9000 [00:25<00:15, 228.38 examples/s]\rTokenizing train dataset:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e             | 5573/9000 [00:25<00:14, 231.70 examples/s]\rTokenizing train dataset:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d             | 5597/9000 [00:25<00:14, 229.94 examples/s]\rTokenizing train dataset:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d             | 5621/9000 [00:26<00:14, 230.65 examples/s]\rTokenizing train dataset:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c             | 5647/9000 [00:26<00:14, 234.03 examples/s]\rTokenizing train dataset:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b             | 5671/9000 [00:26<00:14, 230.64 examples/s]\rTokenizing train dataset:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a             | 5705/9000 [00:26<00:14, 224.25 examples/s]\rTokenizing train dataset:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589             | 5729/9000 [00:26<00:14, 224.86 examples/s]\rTokenizing train dataset:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588             | 5754/9000 [00:26<00:14, 229.60 examples/s]\rTokenizing train dataset:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f            | 5786/9000 [00:26<00:14, 221.50 examples/s]\rTokenizing train dataset:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f            | 5811/9000 [00:26<00:14, 226.21 examples/s]\rTokenizing train dataset:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 5835/9000 [00:26<00:13, 229.15 examples/s]\rTokenizing train dataset:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d            | 5860/9000 [00:27<00:13, 233.95 examples/s]\rTokenizing train dataset:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c            | 5895/9000 [00:27<00:13, 227.59 examples/s]\rTokenizing train dataset:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b            | 5919/9000 [00:27<00:13, 227.32 examples/s]\rTokenizing train dataset:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a            | 5946/9000 [00:27<00:12, 236.37 examples/s]\rTokenizing train dataset:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589            | 5971/9000 [00:27<00:12, 238.27 examples/s]\rTokenizing train dataset:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589            | 5996/9000 [00:27<00:12, 239.72 examples/s]\rTokenizing train dataset:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588            | 6025/9000 [00:27<00:15, 193.94 examples/s]\rTokenizing train dataset:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f           | 6047/9000 [00:27<00:15, 196.52 examples/s]\rTokenizing train dataset:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e           | 6070/9000 [00:28<00:14, 202.78 examples/s]\rTokenizing train dataset:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d           | 6101/9000 [00:28<00:14, 201.41 examples/s]\rTokenizing train dataset:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d           | 6124/9000 [00:28<00:14, 205.37 examples/s]\rTokenizing train dataset:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c           | 6147/9000 [00:28<00:13, 209.85 examples/s]\rTokenizing train dataset:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b           | 6170/9000 [00:28<00:13, 213.92 examples/s]\rTokenizing train dataset:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a           | 6195/9000 [00:28<00:12, 218.53 examples/s]\rTokenizing train dataset:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589           | 6219/9000 [00:28<00:12, 222.20 examples/s]\rTokenizing train dataset:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588           | 6254/9000 [00:28<00:12, 223.07 examples/s]\rTokenizing train dataset:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f          | 6288/9000 [00:29<00:12, 222.32 examples/s]\rTokenizing train dataset:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e          | 6313/9000 [00:29<00:11, 227.65 examples/s]\rTokenizing train dataset:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d          | 6345/9000 [00:29<00:11, 221.44 examples/s]\rTokenizing train dataset:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d          | 6368/9000 [00:29<00:12, 219.08 examples/s]\rTokenizing train dataset:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c          | 6393/9000 [00:29<00:11, 223.66 examples/s]\rTokenizing train dataset:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b          | 6427/9000 [00:29<00:11, 221.36 examples/s]\rTokenizing train dataset:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 6460/9000 [00:29<00:11, 219.09 examples/s]\rTokenizing train dataset:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589          | 6485/9000 [00:29<00:11, 222.88 examples/s]\rTokenizing train dataset:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588          | 6508/9000 [00:30<00:11, 221.72 examples/s]\rTokenizing train dataset:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588          | 6531/9000 [00:30<00:11, 218.52 examples/s]\rTokenizing train dataset:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f         | 6556/9000 [00:30<00:10, 224.79 examples/s]\rTokenizing train dataset:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e         | 6581/9000 [00:30<00:10, 228.64 examples/s]\rTokenizing train dataset:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 6605/9000 [00:30<00:10, 229.58 examples/s]\rTokenizing train dataset:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c         | 6632/9000 [00:30<00:09, 239.06 examples/s]\rTokenizing train dataset:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b         | 6659/9000 [00:30<00:09, 243.19 examples/s]\rTokenizing train dataset:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a         | 6690/9000 [00:30<00:10, 225.25 examples/s]\rTokenizing train dataset:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589         | 6722/9000 [00:31<00:10, 219.00 examples/s]\rTokenizing train dataset:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588         | 6758/9000 [00:31<00:10, 222.27 examples/s]\rTokenizing train dataset:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f        | 6782/9000 [00:31<00:09, 224.83 examples/s]\rTokenizing train dataset:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f        | 6807/9000 [00:31<00:09, 230.17 examples/s]\rTokenizing train dataset:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e        | 6842/9000 [00:31<00:09, 229.84 examples/s]\rTokenizing train dataset:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 6872/9000 [00:31<00:09, 217.45 examples/s]\rTokenizing train dataset:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c        | 6896/9000 [00:31<00:09, 217.48 examples/s]\rTokenizing train dataset:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b        | 6920/9000 [00:31<00:09, 220.62 examples/s]\rTokenizing train dataset:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a        | 6944/9000 [00:32<00:09, 221.82 examples/s]\rTokenizing train dataset:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589        | 6978/9000 [00:32<00:09, 219.58 examples/s]\rTokenizing train dataset:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588        | 7010/9000 [00:32<00:10, 184.66 examples/s]\rTokenizing train dataset:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f       | 7034/9000 [00:32<00:10, 192.41 examples/s]\rTokenizing train dataset:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f       | 7060/9000 [00:32<00:09, 206.29 examples/s]\rTokenizing train dataset:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e       | 7083/9000 [00:32<00:09, 208.14 examples/s]\rTokenizing train dataset:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d       | 7109/9000 [00:32<00:08, 216.43 examples/s]\rTokenizing train dataset:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c       | 7133/9000 [00:32<00:08, 221.24 examples/s]\rTokenizing train dataset:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b       | 7158/9000 [00:33<00:08, 226.31 examples/s]\rTokenizing train dataset:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b       | 7184/9000 [00:33<00:07, 230.78 examples/s]\rTokenizing train dataset:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589       | 7219/9000 [00:33<00:07, 227.53 examples/s]\rTokenizing train dataset:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589       | 7245/9000 [00:33<00:07, 232.23 examples/s]\rTokenizing train dataset:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588       | 7276/9000 [00:33<00:07, 220.87 examples/s]\rTokenizing train dataset:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f      | 7300/9000 [00:33<00:07, 222.00 examples/s]\rTokenizing train dataset:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e      | 7324/9000 [00:33<00:07, 222.24 examples/s]\rTokenizing train dataset:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d      | 7349/9000 [00:33<00:07, 227.90 examples/s]\rTokenizing train dataset:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d      | 7373/9000 [00:33<00:07, 228.98 examples/s]\rTokenizing train dataset:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c      | 7397/9000 [00:34<00:07, 227.00 examples/s]\rTokenizing train dataset:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b      | 7421/9000 [00:34<00:06, 227.36 examples/s]\rTokenizing train dataset:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a      | 7446/9000 [00:34<00:06, 230.96 examples/s]\rTokenizing train dataset:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589      | 7479/9000 [00:34<00:06, 224.76 examples/s]\rTokenizing train dataset:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      | 7504/9000 [00:34<00:06, 228.18 examples/s]\rTokenizing train dataset:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      | 7528/9000 [00:34<00:06, 227.47 examples/s]\rTokenizing train dataset:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f     | 7551/9000 [00:34<00:06, 225.76 examples/s]\rTokenizing train dataset:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e     | 7584/9000 [00:34<00:06, 219.57 examples/s]\rTokenizing train dataset:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d     | 7607/9000 [00:35<00:06, 218.09 examples/s]\rTokenizing train dataset:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c     | 7630/9000 [00:35<00:06, 218.95 examples/s]\rTokenizing train dataset:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b     | 7663/9000 [00:35<00:06, 217.47 examples/s]\rTokenizing train dataset:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b     | 7685/9000 [00:35<00:06, 215.51 examples/s]\rTokenizing train dataset:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a     | 7707/9000 [00:35<00:05, 216.23 examples/s]\rTokenizing train dataset:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 7731/9000 [00:35<00:05, 215.97 examples/s]\rTokenizing train dataset:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588     | 7755/9000 [00:35<00:05, 219.22 examples/s]\rTokenizing train dataset:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588     | 7780/9000 [00:35<00:05, 224.21 examples/s]\rTokenizing train dataset:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f    | 7803/9000 [00:35<00:05, 223.89 examples/s]\rTokenizing train dataset:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e    | 7826/9000 [00:36<00:05, 224.20 examples/s]\rTokenizing train dataset:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d    | 7859/9000 [00:36<00:05, 219.67 examples/s]\rTokenizing train dataset:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c    | 7882/9000 [00:36<00:05, 219.87 examples/s]\rTokenizing train dataset:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c    | 7905/9000 [00:36<00:04, 220.98 examples/s]\rTokenizing train dataset:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b    | 7929/9000 [00:36<00:04, 222.02 examples/s]\rTokenizing train dataset:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a    | 7952/9000 [00:36<00:04, 218.22 examples/s]\rTokenizing train dataset:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589    | 7976/9000 [00:36<00:04, 221.45 examples/s]\rTokenizing train dataset:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589    | 7999/9000 [00:36<00:04, 222.10 examples/s]\rTokenizing train dataset:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 8033/9000 [00:37<00:05, 176.80 examples/s]\rTokenizing train dataset:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 8059/9000 [00:37<00:04, 190.32 examples/s]\rTokenizing train dataset:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 8082/9000 [00:37<00:04, 198.12 examples/s]\rTokenizing train dataset:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 8105/9000 [00:37<00:04, 202.67 examples/s]\rTokenizing train dataset:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 8137/9000 [00:37<00:04, 204.42 examples/s]\rTokenizing train dataset:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 8167/9000 [00:37<00:04, 200.32 examples/s]\rTokenizing train dataset:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 8188/9000 [00:37<00:04, 200.34 examples/s]\rTokenizing train dataset:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 8215/9000 [00:37<00:03, 214.11 examples/s]\rTokenizing train dataset:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 8240/9000 [00:38<00:03, 222.20 examples/s]\rTokenizing train dataset:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 8263/9000 [00:38<00:03, 222.30 examples/s]\rTokenizing train dataset:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 8287/9000 [00:38<00:03, 222.97 examples/s]\rTokenizing train dataset:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 8313/9000 [00:38<00:03, 228.54 examples/s]\rTokenizing train dataset:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 8348/9000 [00:38<00:02, 228.00 examples/s]\rTokenizing train dataset:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 8381/9000 [00:38<00:02, 221.18 examples/s]\rTokenizing train dataset:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 8406/9000 [00:38<00:02, 223.71 examples/s]\rTokenizing train dataset:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 8432/9000 [00:38<00:02, 229.32 examples/s]\rTokenizing train dataset:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 8457/9000 [00:38<00:02, 232.37 examples/s]\rTokenizing train dataset:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 8491/9000 [00:39<00:02, 226.82 examples/s]\rTokenizing train dataset:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8514/9000 [00:39<00:02, 225.14 examples/s]\rTokenizing train dataset:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 8546/9000 [00:39<00:02, 217.64 examples/s]\rTokenizing train dataset:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 8573/9000 [00:39<00:01, 227.42 examples/s]\rTokenizing train dataset:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 8605/9000 [00:39<00:01, 221.29 examples/s]\rTokenizing train dataset:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 8628/9000 [00:39<00:01, 218.57 examples/s]\rTokenizing train dataset:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 8652/9000 [00:39<00:01, 219.14 examples/s]\rTokenizing train dataset:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 8675/9000 [00:39<00:01, 217.72 examples/s]\rTokenizing train dataset:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 8698/9000 [00:40<00:01, 217.83 examples/s]\rTokenizing train dataset:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 8720/9000 [00:40<00:01, 215.11 examples/s]\rTokenizing train dataset:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 8742/9000 [00:40<00:01, 215.61 examples/s]\rTokenizing train dataset:  97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 8765/9000 [00:40<00:01, 215.63 examples/s]\rTokenizing train dataset:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 8787/9000 [00:40<00:00, 214.05 examples/s]\rTokenizing train dataset:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 8809/9000 [00:40<00:00, 215.22 examples/s]\rTokenizing train dataset:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 8840/9000 [00:40<00:00, 209.63 examples/s]\rTokenizing train dataset:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 8863/9000 [00:40<00:00, 211.22 examples/s]\rTokenizing train dataset:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 8887/9000 [00:40<00:00, 214.77 examples/s]\rTokenizing train dataset:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 8909/9000 [00:41<00:00, 215.45 examples/s]\rTokenizing train dataset:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 8934/9000 [00:41<00:00, 222.95 examples/s]\rTokenizing train dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 8958/9000 [00:41<00:00, 225.10 examples/s]\rTokenizing train dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 8984/9000 [00:41<00:00, 232.60 examples/s]\rTokenizing train dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9000/9000 [00:41<00:00, 216.79 examples/s]\n",
            "\rTruncating train dataset:   0%|                                                | 0/9000 [00:00<?, ? examples/s]\rTruncating train dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9000/9000 [00:00<00:00, 162984.05 examples/s]\n",
            "\rApplying formatting function to eval dataset:   0%|                            | 0/1000 [00:00<?, ? examples/s]\rApplying formatting function to eval dataset:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 686/1000 [00:00<00:00, 6806.41 examples/s]\rApplying formatting function to eval dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:00<00:00, 5869.84 examples/s]\n",
            "\rAdding EOS to eval dataset:   0%|                                              | 0/1000 [00:00<?, ? examples/s]\rAdding EOS to eval dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:00<00:00, 10585.34 examples/s]\n",
            "\rTokenizing eval dataset:   0%|                                                 | 0/1000 [00:00<?, ? examples/s]\rTokenizing eval dataset:   2%|\u258b                                      | 17/1000 [00:00<00:06, 160.58 examples/s]\rTokenizing eval dataset:   4%|\u2588\u258c                                     | 39/1000 [00:00<00:05, 186.55 examples/s]\rTokenizing eval dataset:   6%|\u2588\u2588\u258e                                    | 60/1000 [00:00<00:04, 190.93 examples/s]\rTokenizing eval dataset:   8%|\u2588\u2588\u2588\u258e                                   | 85/1000 [00:00<00:04, 209.51 examples/s]\rTokenizing eval dataset:  11%|\u2588\u2588\u2588\u2588                                  | 107/1000 [00:00<00:04, 211.96 examples/s]\rTokenizing eval dataset:  14%|\u2588\u2588\u2588\u2588\u2588\u258d                                | 142/1000 [00:00<00:03, 215.14 examples/s]\rTokenizing eval dataset:  16%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e                               | 165/1000 [00:00<00:03, 215.16 examples/s]\rTokenizing eval dataset:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                              | 189/1000 [00:00<00:03, 216.67 examples/s]\rTokenizing eval dataset:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                              | 212/1000 [00:01<00:03, 216.34 examples/s]\rTokenizing eval dataset:  23%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                             | 234/1000 [00:01<00:03, 215.88 examples/s]\rTokenizing eval dataset:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                            | 258/1000 [00:01<00:03, 218.04 examples/s]\rTokenizing eval dataset:  28%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                           | 283/1000 [00:01<00:03, 223.08 examples/s]\rTokenizing eval dataset:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                          | 313/1000 [00:01<00:03, 212.52 examples/s]\rTokenizing eval dataset:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                         | 345/1000 [00:01<00:03, 208.36 examples/s]\rTokenizing eval dataset:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                        | 367/1000 [00:01<00:03, 207.71 examples/s]\rTokenizing eval dataset:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                       | 392/1000 [00:01<00:02, 217.11 examples/s]\rTokenizing eval dataset:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                      | 415/1000 [00:01<00:02, 219.53 examples/s]\rTokenizing eval dataset:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                    | 451/1000 [00:02<00:02, 223.79 examples/s]\rTokenizing eval dataset:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 474/1000 [00:02<00:02, 223.48 examples/s]\rTokenizing eval dataset:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                  | 507/1000 [00:02<00:02, 219.01 examples/s]\rTokenizing eval dataset:  53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                 | 533/1000 [00:02<00:02, 225.60 examples/s]\rTokenizing eval dataset:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                | 564/1000 [00:02<00:02, 215.50 examples/s]\rTokenizing eval dataset:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e               | 587/1000 [00:02<00:01, 216.01 examples/s]\rTokenizing eval dataset:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f              | 611/1000 [00:02<00:01, 220.85 examples/s]\rTokenizing eval dataset:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d             | 643/1000 [00:02<00:01, 214.83 examples/s]\rTokenizing eval dataset:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 667/1000 [00:03<00:01, 216.63 examples/s]\rTokenizing eval dataset:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e           | 692/1000 [00:03<00:01, 221.13 examples/s]\rTokenizing eval dataset:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d          | 723/1000 [00:03<00:01, 212.37 examples/s]\rTokenizing eval dataset:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e         | 746/1000 [00:03<00:01, 213.90 examples/s]\rTokenizing eval dataset:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f        | 768/1000 [00:03<00:01, 212.94 examples/s]\rTokenizing eval dataset:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f       | 793/1000 [00:03<00:00, 220.37 examples/s]\rTokenizing eval dataset:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d      | 826/1000 [00:03<00:00, 218.75 examples/s]\rTokenizing eval dataset:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d     | 852/1000 [00:03<00:00, 227.47 examples/s]\rTokenizing eval dataset:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c    | 884/1000 [00:04<00:00, 219.92 examples/s]\rTokenizing eval dataset:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 908/1000 [00:04<00:00, 218.80 examples/s]\rTokenizing eval dataset:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 933/1000 [00:04<00:00, 221.77 examples/s]\rTokenizing eval dataset:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 958/1000 [00:04<00:00, 225.62 examples/s]\rTokenizing eval dataset:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 990/1000 [00:04<00:00, 219.88 examples/s]\rTokenizing eval dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:04<00:00, 212.56 examples/s]\n",
            "\rTruncating eval dataset:   0%|                                                 | 0/1000 [00:00<?, ? examples/s]\rTruncating eval dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:00<00:00, 115085.86 examples/s]\n",
            "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "trainer.train()\n",
        "\n",
        "# 9. L\u01b0u model\n",
        "output_dir = \"./final-lora-model\"\n",
        "trainer.model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"\\nModel \u0111\u00e3 l\u01b0u t\u1ea1i: {output_dir}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4500/4500 3:36:20, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Entropy</th>\n      <th>Num Tokens</th>\n      <th>Mean Token Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>1.661100</td>\n      <td>1.624548</td>\n      <td>1.628125</td>\n      <td>1254935.000000</td>\n      <td>0.621200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.620500</td>\n      <td>1.590141</td>\n      <td>1.604408</td>\n      <td>2504420.000000</td>\n      <td>0.626947</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.600600</td>\n      <td>1.572178</td>\n      <td>1.592088</td>\n      <td>3769621.000000</td>\n      <td>0.629989</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.586500</td>\n      <td>1.560602</td>\n      <td>1.572962</td>\n      <td>5023543.000000</td>\n      <td>0.631879</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.587000</td>\n      <td>1.552068</td>\n      <td>1.573938</td>\n      <td>6278472.000000</td>\n      <td>0.633564</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.565700</td>\n      <td>1.545771</td>\n      <td>1.536791</td>\n      <td>7543878.000000</td>\n      <td>0.634596</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.524500</td>\n      <td>1.541566</td>\n      <td>1.538361</td>\n      <td>8799515.000000</td>\n      <td>0.635473</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.524500</td>\n      <td>1.537109</td>\n      <td>1.552449</td>\n      <td>10064850.000000</td>\n      <td>0.636163</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.557200</td>\n      <td>1.532644</td>\n      <td>1.543285</td>\n      <td>11310255.000000</td>\n      <td>0.637150</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.494400</td>\n      <td>1.530351</td>\n      <td>1.526271</td>\n      <td>12575140.000000</td>\n      <td>0.637897</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>1.477200</td>\n      <td>1.526084</td>\n      <td>1.532008</td>\n      <td>13824294.000000</td>\n      <td>0.638612</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.483600</td>\n      <td>1.526273</td>\n      <td>1.513306</td>\n      <td>15064022.000000</td>\n      <td>0.638786</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>1.518800</td>\n      <td>1.525747</td>\n      <td>1.531760</td>\n      <td>16325390.000000</td>\n      <td>0.638538</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.501100</td>\n      <td>1.524294</td>\n      <td>1.516697</td>\n      <td>17586916.000000</td>\n      <td>0.639057</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.501900</td>\n      <td>1.522778</td>\n      <td>1.519537</td>\n      <td>18845611.000000</td>\n      <td>0.639513</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>1.533400</td>\n      <td>1.520929</td>\n      <td>1.524684</td>\n      <td>20094581.000000</td>\n      <td>0.639713</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>1.456700</td>\n      <td>1.520627</td>\n      <td>1.501611</td>\n      <td>21349561.000000</td>\n      <td>0.639955</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>1.510300</td>\n      <td>1.521001</td>\n      <td>1.499662</td>\n      <td>22595654.000000</td>\n      <td>0.639831</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>1.473200</td>\n      <td>1.520459</td>\n      <td>1.503826</td>\n      <td>23858033.000000</td>\n      <td>0.639924</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.477100</td>\n      <td>1.520373</td>\n      <td>1.498458</td>\n      <td>25100623.000000</td>\n      <td>0.640006</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>1.462900</td>\n      <td>1.520353</td>\n      <td>1.498192</td>\n      <td>26364519.000000</td>\n      <td>0.640080</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>1.459600</td>\n      <td>1.520300</td>\n      <td>1.499567</td>\n      <td>27633276.000000</td>\n      <td>0.640132</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model \u0111\u00e3 l\u01b0u t\u1ea1i: ./final-lora-model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# ...existing code...\n",
        "# Ch\u1ecdn m\u1ed9t m\u1eabu b\u1ea5t k\u1ef3 t\u1eeb t\u1eadp test (v\u00ed d\u1ee5 m\u1eabu \u0111\u1ea7u ti\u00ean)\n",
        "sample = test_data[400]\n",
        "document = sample['Document']\n",
        "ground_truth = sample['Summary']\n",
        "\n",
        "# T\u1ea1o messages cho inference (L\u01b0u \u00fd: Kh\u00f4ng bao g\u1ed3m ph\u1ea7n 'assistant' ch\u1ee9a t\u00f3m t\u1eaft m\u1eabu)\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"B\u1ea1n l\u00e0 m\u1ed9t bi\u00ean t\u1eadp vi\u00ean b\u00e1o ch\u00ed chuy\u00ean nghi\u1ec7p. Nhi\u1ec7m v\u1ee5 c\u1ee7a b\u1ea1n l\u00e0 t\u00f3m t\u1eaft b\u00e0i b\u00e1o \u0111\u01b0\u1ee3c cung c\u1ea5p. \"},\n",
        "    {\"role\": \"user\", \"content\": document}\n",
        "]\n",
        "\n",
        "# Tokenize input v\u00e0 \u0111\u01b0a l\u00ean thi\u1ebft b\u1ecb (GPU)\n",
        "input_ids = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "# Sinh v\u0103n b\u1ea3n (Generate)\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens = 666,\n",
        "    temperature=0.1,         # \u0110\u1ed9 s\u00e1ng t\u1ea1o\n",
        "    top_p=0.9,\n",
        "    do_sample=True,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Decode k\u1ebft qu\u1ea3 (c\u1eaft b\u1ecf ph\u1ea7n prompt input ban \u0111\u1ea7u \u0111\u1ec3 ch\u1ec9 l\u1ea5y ph\u1ea7n model sinh ra)\n",
        "response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"V\u0103n b\u1ea3n g\u1ed1c:\\n{document}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"T\u00f3m t\u1eaft g\u1ed1c (Ground Truth):\\n{ground_truth}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"M\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n:\\n{response}\")\n",
        "print(\"-\" * 50)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "V\u0103n b\u1ea3n g\u1ed1c (500 k\u00fd t\u1ef1 \u0111\u1ea7u):\n",
            "Trong n\u0103m 2016 , \u01b0\u1edbc t\u00ednh 600.000 tr\u1ebb em \u0111\u00e3 t\u1eed vong do nhi\u1ec5m tr\u00f9ng \u0111\u01b0\u1eddng h\u00f4 h\u1ea5p d\u01b0\u1edbi c\u1ea5p t\u00ednh g\u00e2y ra b\u1edfi kh\u00f4ng kh\u00ed \u00f4 nhi\u1ec5m .\u00d4 nhi\u1ec5m kh\u00f4ng kh\u00ed l\u00e0 m\u1ed9t trong nh\u1eefng m\u1ed1i \u0111e do\u1ea1 h\u00e0ng \u0111\u1ea7u \u0111\u1ed1i v\u1edbi s\u1ee9c kho\u1ebb \u1edf tr\u1ebb em d\u01b0\u1edbi 5 tu\u1ed5i , chi\u1ebfm g\u1ea7n 1 trong 10 ca t\u1eed vong \u1edf nh\u00f3m tu\u1ed5i n\u00e0y , b\u00e1o c\u00e1o cho bi\u1ebft .Theo WHO , tr\u1ebb em d\u1ec5 b\u1ecb \u00f4 nhi\u1ec5m h\u01a1n v\u00ec chi\u1ec1u cao th\u1ea5p h\u01a1n ng\u01b0\u1eddi tr\u01b0\u1edfng th\u00e0nh n\u00ean s\u1ebd h\u00edt v\u00e0o c\u01a1 th\u1ec3 c\u00e1c ch\u1ea5t \u0111\u1ed9c h\u1ea1i g\u1ea7n m\u1eb7t \u0111\u1ea5t nhi\u1ec1u h\u01a1n ng\u01b0\u1eddi tr\u01b0\u1edfng th\u00e0nh .T\u1ea1i c\u00e1c n\u01b0\u1edbc thu nh\u1eadp th\u1ea5p v\u00e0 trung b\u00ecnh , 98 % tr\u1ebb em d\u01b0\u1edbi 5 tu\u1ed5i th\u01b0\u1eddng xuy\u00ean ti\u1ebfp x\u00fac v\u1edbi b\u1ee5i si\u00eau vi PM 2.5 .C\u00f2n \u1edf c\u00e1c n\u01b0\u1edbc c\u00f3 thu nh\u1eadp cao , 52 % tr\u1ebb em d\u01b0\u1edbi 5 tu\u1ed5i ti\u1ebfp x\u00fac v\u1edbi PM 2.5 .Ti\u1ebfn s\u0129 Maria Neira , gi\u00e1m \u0111\u1ed1c S\u1edf Y t\u1ebf c\u00f4ng c\u1ed9ng , m\u00f4i tr\u01b0\u1eddng v\u00e0 x\u00e3 h\u1ed9i ( WHO ) , cho bi\u1ebft : \" \u00d4 nhi\u1ec5m kh\u00f4ng kh\u00ed l\u00e0m n\u00e3o tr\u1ebb em ch\u1eadm ph\u00e1t tri\u1ec3n , \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn s\u1ee9c kho\u1ebb c\u1ee7a ch\u00fang theo nhi\u1ec1u c\u00e1ch h\u01a1n ch\u00fang ta bi\u1ebft \" .T\u1ed5 ch\u1ee9c WHO \u0111\u01b0a ra m\u1ed9t lo\u1ea1t h\u00e0nh \u0111\u1ed9ng c\u1ea7n thi\u1ebft \u0111\u1ec3 h\u1ea1n ch\u1ebf v\u1ea5n \u0111\u1ec1 \u00f4 nhi\u1ec5m kh\u00f4ng kh\u00ed v\u00e0 b\u1ea3o v\u1ec7 s\u1ee9c kho\u1ebb tr\u1ebb em tr\u00ean to\u00e0n th\u1ebf gi\u1edbi .\u0110\u00f3 l\u00e0 th\u1ef1c hi\u1ec7n c\u00e1c ch\u00ednh s\u00e1ch m\u1edbi \u0111\u1ec3 gi\u1ea3m m\u1ee9c \u00f4 nhi\u1ec5m , nh\u01b0 gi\u1ea3m s\u1ef1 ph\u1ee5 thu\u1ed9c v\u00e0o nhi\u00ean li\u1ec7u ho\u00e1 th\u1ea1ch , t\u0103ng c\u01b0\u1eddng s\u1eed d\u1ee5ng n\u0103ng l\u01b0\u1ee3ng t\u00e1i t\u1ea1o t\u00e0i nguy\u00ean .N\u00e2ng cao tr\u00e1ch nhi\u1ec7m trong vi\u1ec7c x\u1eed l\u00fd ch\u1ea5t th\u1ea3i t\u1ea1i c\u00e1c qu\u1ed1c gia .X\u00e2y d\u1ef1ng tr\u01b0\u1eddng h\u1ecdc v\u00e0 s\u00e2n ch\u01a1i c\u00e1ch xa c\u00e1c con \u0111\u01b0\u1eddng v\u00e0 nh\u00e0 m\u00e1y b\u1eadn r\u1ed9n .\" WHO \u0111ang h\u1ed7 tr\u1ee3 th\u1ef1c hi\u1ec7n c\u00e1c bi\u1ec7n ph\u00e1p ch\u00ednh s\u00e1ch y t\u1ebf nh\u01b0 \u0111\u1ea9y nhanh chuy\u1ec3n \u0111\u1ed5i c\u00f4ng ngh\u1ec7 , nhi\u00ean li\u1ec7u n\u1ea5u n\u01b0\u1edbng v\u00e0 s\u01b0\u1edfi \u1ea5m , th\u00fac \u0111\u1ea9y vi\u1ec7c s\u1eed d\u1ee5ng ph\u01b0\u01a1ng ti\u1ec7n v\u1eadn chuy\u1ec3n s\u1ea1ch h\u01a1n , nh\u00e0 \u1edf ti\u1ebft ki\u1ec7m n\u0103ng l\u01b0\u1ee3ng v\u00e0 quy ho\u1ea1ch \u0111\u00f4 th\u1ecb .Ch\u00fang t\u00f4i \u0111ang chu\u1ea9n b\u1ecb n\u1ec1n t\u1ea3ng cho ph\u00e1t \u0111i\u1ec7n n\u0103ng l\u01b0\u1ee3ng th\u1ea5p , c\u00f4ng ngh\u1ec7 s\u1ea1ch h\u01a1n , an to\u00e0n h\u01a1n v\u00e0 qu\u1ea3n l\u00fd ch\u1ea5t th\u1ea3i \u0111\u00f4 th\u1ecb t\u1ed1t h\u01a1n \" - ti\u1ebfn s\u0129 Maria Neira cho bi\u1ebft ....\n",
            "--------------------------------------------------\n",
            "T\u00f3m t\u1eaft g\u1ed1c (Ground Truth):\n",
            "Theo b\u00e1o c\u00e1o c\u1ee7a WHO, \u00f4 nhi\u1ec5m kh\u00f4ng kh\u00ed l\u00e0 m\u1ed9t trong nh\u1eefng m\u1ed1i \u0111e d\u1ecda h\u00e0ng \u0111\u1ea7u \u0111\u1ebfn s\u1ee9c kh\u1ecfe tr\u1ebb em d\u01b0\u1edbi 5 tu\u1ed5i, g\u00e2y ra kho\u1ea3ng 600.000 ca t\u1eed vong do nhi\u1ec5m tr\u00f9ng \u0111\u01b0\u1eddng h\u00f4 h\u1ea5p d\u01b0\u1edbi c\u1ea5p t\u00ednh v\u00e0o n\u0103m 2016, chi\u1ebfm g\u1ea7n 10% t\u1ed5ng s\u1ed1 ca t\u1eed vong \u1edf \u0111\u1ed9 tu\u1ed5i n\u00e0y. Tr\u1ebb em d\u1ec5 b\u1ecb \u1ea3nh h\u01b0\u1edfng b\u1edfi \u00f4 nhi\u1ec5m h\u01a1n ng\u01b0\u1eddi l\u1edbn do chi\u1ec1u cao v\u00e0 v\u1ecb tr\u00ed g\u1ea7n m\u1eb7t \u0111\u1ea5t, khi\u1ebfn ch\u00fang h\u00edt ph\u1ea3i nhi\u1ec1u ch\u1ea5t \u0111\u1ed9c h\u1ea1i h\u01a1n. T\u1ea1i c\u00e1c n\u01b0\u1edbc thu nh\u1eadp th\u1ea5p v\u00e0 trung b\u00ecnh, 98% tr\u1ebb d\u01b0\u1edbi 5 tu\u1ed5i th\u01b0\u1eddng xuy\u00ean ti\u1ebfp x\u00fac v\u1edbi b\u1ee5i si\u00eau vi PM2.5, so v\u1edbi 52% \u1edf c\u00e1c n\u01b0\u1edbc c\u00f3 thu nh\u1eadp cao. Ti\u1ebfn s\u0129 Maria Neira nh\u1ea5n m\u1ea1nh \u00f4 nhi\u1ec5m kh\u00f4ng kh\u00ed c\u00f3 th\u1ec3 l\u00e0m ch\u1eadm s\u1ef1 ph\u00e1t tri\u1ec3n n\u00e3o b\u1ed9 v\u00e0 \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn s\u1ee9c kh\u1ecfe tr\u1ebb em theo nhi\u1ec1u c\u00e1ch. WHO k\u00eau g\u1ecdi th\u1ef1c hi\u1ec7n c\u00e1c ch\u00ednh s\u00e1ch gi\u1ea3m \u00f4 nhi\u1ec5m, chuy\u1ec3n \u0111\u1ed5i n\u0103ng l\u01b0\u1ee3ng v\u00e0 c\u1ea3i thi\u1ec7n quy ho\u1ea1ch \u0111\u00f4 th\u1ecb \u0111\u1ec3 b\u1ea3o v\u1ec7 s\u1ee9c kh\u1ecfe tr\u1ebb em to\u00e0n c\u1ea7u.\n",
            "--------------------------------------------------\n",
            "M\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n:\n",
            "N\u0103m 2016, \u01b0\u1edbc t\u00ednh c\u00f3 kho\u1ea3ng 600.000 tr\u1ebb em t\u1eed vong do nhi\u1ec5m tr\u00f9ng \u0111\u01b0\u1eddng h\u00f4 h\u1ea5p d\u01b0\u1edbi c\u1ea5p t\u00ednh do \u00f4 nhi\u1ec5m kh\u00f4ng kh\u00ed g\u00e2y ra. Theo b\u00e1o c\u00e1o c\u1ee7a WHO, \u00f4 nhi\u1ec5m kh\u00f4ng kh\u00ed l\u00e0 m\u1ed9t trong nh\u1eefng m\u1ed1i \u0111e d\u1ecda h\u00e0ng \u0111\u1ea7u \u0111\u1ed1i v\u1edbi s\u1ee9c kh\u1ecfe c\u1ee7a tr\u1ebb em d\u01b0\u1edbi 5 tu\u1ed5i, chi\u1ebfm g\u1ea7n 1/10 s\u1ed1 ca t\u1eed vong trong nh\u00f3m n\u00e0y. Tr\u1ebb em d\u1ec5 b\u1ecb \u00f4 nhi\u1ec5m h\u01a1n ng\u01b0\u1eddi l\u1edbn do chi\u1ec1u cao th\u1ea5p, v\u00e0 t\u1ea1i c\u00e1c n\u01b0\u1edbc thu nh\u1eadp th\u1ea5p v\u00e0 trung b\u00ecnh, 98% tr\u1ebb em d\u01b0\u1edbi 5 tu\u1ed5i ti\u1ebfp x\u00fac v\u1edbi b\u1ee5i si\u00eau vi PM2.5, trong khi \u1edf c\u00e1c n\u01b0\u1edbc c\u00f3 thu nh\u1eadp cao, t\u1ef7 l\u1ec7 n\u00e0y l\u00e0 52%. WHO khuy\u1ebfn ngh\u1ecb c\u00e1c ch\u00ednh s\u00e1ch gi\u1ea3m \u00f4 nhi\u1ec5m, chuy\u1ec3n \u0111\u1ed5i sang n\u0103ng l\u01b0\u1ee3ng t\u00e1i t\u1ea1o v\u00e0 c\u1ea3i thi\u1ec7n quy ho\u1ea1ch \u0111\u00f4 th\u1ecb \u0111\u1ec3 b\u1ea3o v\u1ec7 s\u1ee9c kh\u1ecfe tr\u1ebb em.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}